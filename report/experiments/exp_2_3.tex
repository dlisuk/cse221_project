To measure the page fault latency we generate a file containing 4MB of data from {\tt /dev/random}, since the page size is 4KB this corresponds to 1000 pages of data.  
We then memory map this file and then measure the latency of reading the first byte of each page.  
This corresponds to a page fault since the memory makes a block of memory and sets the file on disk to function as it's swapped page source.
Thus when we request a byte from the region which has not been brough into memory it is the same as a page fault.
In our later disk experiments, sequential reading of disk blocks, which have the same size and access pattern as we see in this experiment, have a mean latency of 250,000 cycles per block.
Since the access pattern is similar to our access pattern here, we expect similar performance; however, a common myth is that memory mapping (as used here) is faster than reading (as used in the disk experiments) due to page faulting using a better system compared to disk io.
Thus our estimate is likely a bit over.

Our experiment showed 150,000 cycles per page fault with a standard deviation of 33,000 cycles.
As expected, this is slightly faster than the performance of regular disk io.
However, it is within the same order of magnitude.